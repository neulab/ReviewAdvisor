{"id": "0", "text": "The paper proposes a new memory access scheme based on Lie group actions for NTMs . Pros : * Well written * Novel addressing scheme as an extension to NTM . * Seems to work slightly better than normal NTMs . * Some interesting theory about the novel addressing scheme based on Lie groups . Cons : * In the results , the LANTM only seems to be slightly better than the normal NTM . * The result tables are a bit confusing . * No source code available . * The difference to the properties of normal NTM does n't become too clear . Esp it is said that LANTM are better than NTM because they are differentiable end-to-end and provide a robust relative indexing scheme but NTM are also differentiable end-to-end and also provide a robust indexing scheme . * It is said that the head is discrete in NTM but actually it is in space R^n , i.e.it is already continuous . It does n't become clear what is meant here . * No tests on real-world tasks , only some toy tasks . * No comparisons to some of the other NTM extensions such as D-NTM or Sparse Access Memory ( SAM ) ( https : //arxiv.org/abs/1610.09027 ) . Although the motivations of other NTM extensions might be different , such comparisons still would have been interesting .", "labels": [[0, 83, "summary"], [93, 105, "clarity_positive"], [108, 156, "originality_positive"], [159, 207, "soundness_positive"], [210, 289, "originality_positive"], [299, 380, "soundness_negative"], [383, 422, "clarity_negative"], [425, 451, "replicability_negative"], [454, 528, "clarity_negative"], [862, 907, "clarity_negative"], [910, 962, "substance_negative"], [965, 1061, "meaningful_comparison_negative"]]}
{"id": "1", "text": "The paper makes an interesting and timely contribution in investigating controlled dataset collection , and the impact of different axes of variation on object detection . In general , the community agrees on the importance of these questions , but there is very little work done to provide answers . As such , the originality and significance of the work is high . Clarity of the paper is also good , and release of the dataset and code should help with reproducibility . *** Post-rebuttal comments After reading the other reviews and the rebuttal , I am more convinced that this paper should be accepted . The rebuttal addressed concerns in a thoughtful and concrete manner .", "labels": [[0, 171, "summary"], [172, 242, "motivation_positive"], [245, 298, "soundness_negative"], [301, 365, "originality_positive"], [366, 399, "clarity_positive"]]}
{"id": "2", "text": "This paper conducts an empirical analysis of the effect of training data size on the model robustness to adversarial examples . The authors compared four different NN architectures using four different datasets for the task of image classification . Overall , the paper is easy to follow and clearly written . However , since Su et al. , 2018 , already presented similar findings , I do not see any major contribution in this paper . Additionally , I would expect the authors to conduct some more analysis of their results besides acc . and distortion levels . For examples , investigate the type of mistakes the models have made , compare models with the same test acc . but different amount of training data used to get there , some analysis/experiments to explain these findings ( monitor models parameters/grads during training , etc . )", "labels": [[0, 249, "summary"], [250, 309, "clarity_positive"], [310, 433, "originality_negative"], [434, 560, "substance_negative"]]}
